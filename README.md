# RL + LLM Trading System

A comprehensive trading system combining Reinforcement Learning (RL) agents with Large Language Model (LLM) capabilities for stock market prediction and trading.

## ğŸ¯ Project Overview

This project implements a hybrid trading system with two main phases:

1. **Phase 1: Traditional RL Trading** - Pure reinforcement learning agents (PPO, DQN, DDPG, TD3) trained on market data
2. **Phase 2: LLM-Enhanced Trading** - Integration of LLM agents for sentiment analysis, strategy planning, and multi-agent decision-making using LangGraph

## ğŸ“ Project Structure

```
rl_llm_trading/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              # Main configuration file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_fetcher.py          # Download market data (yfinance, Alpaca)
â”‚   â”œâ”€â”€ data_processor.py        # Feature engineering & preprocessing
â”‚   â””â”€â”€ news_fetcher.py          # Fetch news & sentiment data
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trading_env.py           # Gym-style trading environment
â”‚   â””â”€â”€ portfolio_env.py         # Portfolio management environment
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ rl/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ppo_agent.py         # PPO implementation
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py         # DQN/DDQN implementation
â”‚   â”‚   â”œâ”€â”€ ddpg_agent.py        # DDPG implementation
â”‚   â”‚   â””â”€â”€ td3_agent.py         # TD3 implementation
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ sentiment_analyzer.py # LLM-based sentiment analysis
â”‚       â”œâ”€â”€ strategy_planner.py   # LLM strategy generation
â”‚       â”œâ”€â”€ multi_agent.py        # Multi-agent LLM system
â”‚       â””â”€â”€ rag_memory.py         # RAG-based memory system
â”œâ”€â”€ models/
â”‚   â””â”€â”€ networks.py              # Neural network architectures
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_loader.py         # Configuration utilities
â”‚   â”œâ”€â”€ metrics.py               # Trading metrics calculation
â”‚   â”œâ”€â”€ visualization.py         # Plotting & visualization
â”‚   â””â”€â”€ logger.py                # Logging utilities
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_rl.py              # Train traditional RL agents
â”‚   â”œâ”€â”€ train_llm_rl.py          # Train LLM-enhanced agents
â”‚   â”œâ”€â”€ backtest.py              # Backtesting script
â”‚   â””â”€â”€ evaluate.py              # Evaluation script
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_*.py                # Unit tests
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

## ğŸš€ Getting Started

### Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd rl_llm_trading

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Environment Setup

1. Create a `.env` file in the root directory:

```bash
# API Keys
ANTHROPIC_API_KEY=your_anthropic_key
OPENAI_API_KEY=your_openai_key
ALPACA_API_KEY=your_alpaca_key
ALPACA_SECRET_KEY=your_alpaca_secret
NEWS_API_KEY=your_news_api_key

# Optional
WANDB_API_KEY=your_wandb_key
```

2. Configure settings in `config/config.yaml`

## ğŸ“Š Phase 1: Traditional RL Trading

### Step 1: Data Preparation

```bash
# Download and preprocess market data
python scripts/prepare_data.py --tickers AAPL GOOGL MSFT --start-date 2020-01-01
```

### Step 2: Train RL Agent

```bash
# Train PPO agent
python scripts/train_rl.py --algorithm ppo --timesteps 500000

# Train DQN agent
python scripts/train_rl.py --algorithm dqn --timesteps 500000

# Train DDPG agent
python scripts/train_rl.py --algorithm ddpg --timesteps 500000
```

### Step 3: Evaluate & Backtest

```bash
# Backtest trained agent
python scripts/backtest.py --model checkpoints/ppo_best.zip --start-date 2023-01-01

# Evaluate performance
python scripts/evaluate.py --model checkpoints/ppo_best.zip
```

## ğŸ¤– Phase 2: LLM-Enhanced Trading

### LLM Integration Patterns

1. **LLM as Feature Extractor**

   - Processes news, filings, social media
   - Generates sentiment scores and event flags
   - Feeds enriched features to RL agent

2. **LLM as Strategy Planner**

   - Generates high-level trading strategies
   - RL agent executes with optimal timing and sizing

3. **Multi-Agent System**
   - Multiple specialized LLM agents (fundamental, technical, sentiment)
   - Collaborative decision-making using LangGraph
   - RL agent or aggregator translates to actions

### Training LLM-Enhanced Agents

```bash
# Train with LLM sentiment features
python scripts/train_llm_rl.py --mode sentiment --algorithm ppo

# Train with LLM strategy planner
python scripts/train_llm_rl.py --mode planner --algorithm td3

# Train multi-agent system
python scripts/train_llm_rl.py --mode multi_agent --algorithm ppo
```

## ğŸ”§ Configuration

Edit `config/config.yaml` to customize:

- **Data sources**: Tickers, date ranges, features
- **Environment**: Initial capital, commission, slippage
- **RL algorithms**: Hyperparameters for PPO, DQN, DDPG, TD3
- **LLM settings**: Provider, model, temperature
- **Risk management**: Position limits, stop loss, max drawdown

## ğŸ“ˆ Key Features

### Traditional RL

- âœ… Multiple RL algorithms (PPO, DQN, DDPG, TD3, SAC)
- âœ… Realistic market simulation (commission, slippage)
- âœ… Technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands)
- âœ… Walk-forward backtesting
- âœ… Comprehensive metrics (Sharpe, Sortino, Max DD)

### LLM Integration

- âœ… Sentiment analysis from news & social media
- âœ… Strategy generation and planning
- âœ… Multi-agent debate and consensus
- âœ… RAG-based memory for historical context
- âœ… LangGraph for agent orchestration

### Risk Management

- âœ… Position sizing limits
- âœ… Stop loss and take profit
- âœ… Maximum drawdown control
- âœ… Volatility targeting

## ğŸ“Š Evaluation Metrics

- **Returns**: Total return, CAGR, excess returns
- **Risk-Adjusted**: Sharpe ratio, Sortino ratio, Calmar ratio
- **Risk**: Maximum drawdown, volatility, VaR, CVaR
- **Trading**: Win rate, profit factor, average trade, turnover

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=. --cov-report=html
```

## ğŸš¨ Important Notes

### Overfitting & Data Leakage

- Use walk-forward backtesting
- Separate train/validation/test sets
- Be cautious of look-ahead bias

### Transaction Costs

- Always include realistic commission and slippage
- Model market impact for large orders

### LLM Considerations

- API costs can be significant
- Latency may affect real-time trading
- Cache LLM outputs when possible

### Regulatory & Ethical

- Algorithmic trading is heavily regulated
- Be aware of market manipulation concerns
- Test thoroughly before live deployment

## ğŸ“š References

- FinRL: https://github.com/AI4Finance-Foundation/FinRL
- Stable Baselines3: https://stable-baselines3.readthedocs.io/
- LangGraph: https://langchain-ai.github.io/langgraph/
- Trading Agents: https://github.com/TauricResearch/TradingAgents
